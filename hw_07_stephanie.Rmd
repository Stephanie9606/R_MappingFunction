---
title: "STAT 413/613: HW on List Columns and  COVID19"
author: "Sihyuan Han"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: yes
    toc_depth: 4
    number_sections: yes
    theme: cerulean
  pdf_document:
    toc: yes
    number_sections: yes
    toc_depth: '4'
params:
  solutions: FALSE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.align  = "center",
                      fig.height = 5, 
                      fig.width  = 6)
```

```{r}
library(readr)
library(broom)
library(tidyverse)
library(stringr)
library(purrr)
library(lubridate)
library(countrycode)
library(ggplot2)
```

# Load global and US confirmed cases and deaths data into a nested data frame
1. Create a variable called `url_in` to store this URL: "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/". This allows you do directly download the files at the John's Hopkins site:  "https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series"
```{r}
url_in <- c("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/")
```

2. Create a tibble named `df` with a variable called `file_names` with a row for each of the following four file names to be loaded from the URL:
    + time_series_covid19_confirmed_global.cs
    + time_series_covid19_deaths_global.csv
    + time_series_covid19_confirmed_US.csv
    + time_series_covid19_deaths_US.csv
```{r}
# glimpse(url_in)

# create a tibble
file_names <- c("time_series_covid19_confirmed_global.csv", "time_series_covid19_deaths_global.csv", "time_series_covid19_confirmed_US.csv", "time_series_covid19_deaths_US.csv")
df <- tibble(file_names)
```

3. Create a variable in the data frame called `url` that puts `url_in` on the front of each file_name to create a complete URL.
```{r}
df %>% 
  mutate(url = str_c(url_in, file_names)) ->
  df
```

4. Use `mutate()` with `map()` to create a list column called `data` with each row holding the downloaded data frame for each file name
```{r}
df %>% 
  mutate(data = map(url, read_csv)) ->
  df
```

5. Add a factor variable to `df` called `"`case_type`"` with the **unique** portions of the file names.
```{r}
df %>% 
  mutate(case_type = str_sub(file_names, start = 21, end = -1)) %>% 
  mutate(case_type = str_remove(case_type, "time_series_covid19_")) %>% 
  mutate(case_type = str_remove(case_type, ".csv")) %>% 
  mutate(case_type = as.factor(case_type)) ->
  df
```

6. Remove any columns other than `case_types` and `data` from `df`.
- `df` should have four observations of two variables.
```{r}
df %>% 
  select(case_type, data) ->
  df
df$data[[3]]
```


# Clean Data  
1. Using a single call to `map()`, add only the first 15 names from each of the four data frames to a new variable in `df` called `vars`.
 - Visually compare them to identify issues across the rows.
```{r}
df %>% 
  mutate(vars = map(data, names)) ->
  df
# check vars
df %>% 
  unnest(vars) %>% 
  group_by(case_type, data) %>% 
  slice(1:15)
```

2. Use a purrr function for each of the following steps (except a) to fix any issues and create consistent data frames.  
a. Create a short helper function called `fix_names()` which takes three arguments: a data frame, a string pattern, and a string "replacement pattern". It should replace all occurrences of the "string pattern" in the names of the variables in the data frame with the "replacement pattern". Include error checking to ensure the inputs are of the proper class.
```{r}
fix_names <- function(dfr, strp, strrep) {
  stopifnot(is.data.frame(dfr), is.character(strp), is.character(strrep))
  names(dfr) <- str_replace_all(names(dfr), strp, strrep)
  return(dfr)
}
```

b. Use your function with `map()` to convert "Province/State" and "Country/Region" to "Province_State" "Country_Region" .
```{r}
df %>% 
  mutate(data = map(data, ~fix_names(., "([ey])/", "\\1_"))) ->
  df
```

c. Use your function with `map()` to convert "Admin2 to "County" and "Long_" to "Long".
```{r}
df %>% 
  mutate(data = map(data, ~fix_names(., "Long_", "Long"))) %>% 
  mutate(data = map(data, ~fix_names(., "Admin2", "County"))) ->
  df
```

d. Use a purrr function to remove the variables "UID", "iso2", "iso3", "code3", "FIPS", and "Combined_Key" from only the US data.
```{r}
df %>% 
  mutate(data = map_if(data, str_detect(case_type, "US"), ~select(., -c("UID", "iso2", "iso3", "code3", "FIPS", "Combined_Key")))) ->
  df
```

e. Use a purrr function to add variables `Population` and `County` to the data frames where missing.
```{r}
df %>% 
  mutate(data = map_if(data, str_detect(case_type, "global"), ~mutate(., County = "NA"))) %>% 
  mutate(data = map_if(data, !str_detect(case_type, "deaths_US"), ~mutate(., Population = 0))) ->
  df
```

f. Use a purrr function to add variable called `Country_State` that combines the country with the province/state while keeping the original columns.
```{r}
df %>% 
  mutate(data = map(data, ~unite(., Country_State, c(Country_Region, Province_State), sep = "_", remove = FALSE, na.rm = TRUE))) ->
  df
```

g. Update the values in `df$vars` with the new first 15 names and show the values to check for consistency in each pair of rows.
```{r}
df %>% 
  mutate(vars = map(data, names)) ->
  df
# check new vars
df %>% 
  unnest(vars) %>% 
  group_by(case_type, data) %>% 
  slice(1:15)
```

- Hint: Look at help for `map_if()`


# Tidy each dataframe 
1. Use `map()` along with `pivot_longer()` to tidy each data frame.
- As part of the pivot, ensure the daily values are in a variable called "`Date`" and use a lubridate function *inside the pivot* to ensure it is of class `date`.
2. Save the new data frame to a variable called `df_long`
```{r}
df %>% 
  mutate(data = map(data, ~pivot_longer(., cols = c(contains("/")),
             names_to = "Date",
             values_to = "Cases",
             names_transform = list(Date = mdy),
             ))) ->
  df_long
```


# Add Continents 
1.  Use `map()` to add a new variable called `Continent` to each data frame.  
- Hint: use the package {countrycode} to get the continents.
- If you don't have it already, use the console to install. 
- Then load package {countrycode} and look at help for `countrycode::countrycode`
- You will get some warning messages about NAs which you will fix next.
```{r}
df_long %>% 
  mutate(data = map(data, ~mutate(., Continent = countrycode(Country_Region, origin = "country.name", destination = "continent")))) ->
  df_long
```


# Fix NAs for Continents
- Use `map()` with `case_when()` to replace the NAs due to "Diamond Princess", "Kosovo", "MS Zaandam" and Micronesia, with the most appropriate continent
- Use `map()` with `unique()` to confirm five continents in the global data frames and one in the US data frames
```{r}
df_long %>% 
  mutate(data = map(data, ~mutate(., Continent = case_when(
    is.na(Continent) ~ "Oceania",
    TRUE ~ as.character(Continent)
  )))) ->
  df_long
# check # need revise
map(df_long$data, ~unique(.$Continent))
```


# Unnest the Data Frames    
1. Unnest and ungroup the data frame `df_long` and save into a new data frame called `df_all`
```{r}
unnest(df_long, data) %>% 
  ungroup() ->
  df_all
```

2. Remove original `df` and `df_long` dataframes from the environment
```{r}
rm(df, df_long)
```

3. Remove the `vars` variable from df_all
```{r}
df_all %>% 
  select(-vars) ->
  df_all
```


# Get World Population Data
1.a.  Use a readr function and relative path to read in the .csv with World population data for 2019 into its own data frame called `df_pop`.  
  - The data is from the [UN](https://population.un.org/wpp/Download/Standard/CSV/) which uses different country names in many cases from the COVID data. It also uses a different structure for separating countries and territories.  
  - The CSV has been adjusted to match the COVID data country names in many cases, e.g., US, and Iran.  
  - Note: the UN population data is in thousands so it can have fractional values. 
```{r}
df_pop <- read_csv("./data/WPP2019_TotalPopulation.csv")
```

1.b. Identify the countries in the Covid data that are not in the population data. 
```{r}
# df_all %>% head() - Country_State
# df_pop %>% head() - Location

anti_join(df_all, df_pop, by = c("Country_Region" = "Location")) %>% 
  distinct(Country_Region)
```

1.c. Identify the countries in the population data that are not in the covid data. How many are there?  
```{r}
anti_join(df_pop, df_all, by = c("Location" = "Country_Region")) %>% 
  distinct(Location) %>% 
  nrow()
```

1.d. What is the percentage of the world population contained in these countries? 
```{r}
anti_join(df_pop, df_all, by = c("Location" = "Country_Region")) %>% 
  summarise(sum_pop = sum(PopTotal))
df_pop %>% 
  summarise(sum_pop = sum(PopTotal))
47675.78/7713468
```

  - Since the percentage is small, we will remove them from the subsequent analysis.

2. Use a dplyr join to remove all Locations that are not in the `df_all` data frame.
```{r}
semi_join(df_pop, df_all, by = c("Location" = "Country_Region")) ->
  df_pop
```

3. Use a dplyr function to add the ranks for each location for population and population density to `df_pop` where the country with the largest value is number 1 for that variables. Show the top 10 countries for Population and for population density.
  + Calculate the ranks using a method where if `n` countries are tied at the same rank, the next rank is `n` greater than the rank with if the ties. As an example, if two countries are tied at 2, the next non-tied country has rank 4.
```{r}
# PopTotal Rank
df_pop %>% 
  mutate(rank_p = min_rank(-PopTotal)) ->
  df_pop
# PopDensity Rank
df_pop %>% 
  mutate(rank_d = min_rank(-PopDensity)) ->
  df_pop
# show the top 10 countries for pop and dens
# pops
df_pop %>% 
  arrange(rank_p) %>% 
  slice(1:10)
# dens
df_pop %>% 
  arrange(rank_d) %>% 
  slice(1:10)
```

4. Create an appropriate plot and then test to assess if there is a linear relationship between ranks for Total Population and Population Density. Interpret the plot and interpret the output from the model in terms of `$p$` value and adjusted R-squared.
```{r}
# need revise
lmout <-  lm(PopTotal ~ PopDensity, data = df_pop)
summary(lmout)
# Based on the output, with p-value < 0.05, it suggests that there is enough evidence to say that there is a linear relationship between ranks for Total Population and Population Density. Adjusted R-squared shows that approximately 20% of the variation is explained by the regression model, so we can say that this is not a good model 
```


# Add Population Data to `df_all`
- Use a dplyr join to add the data from `df_pop` to `df_all` to create `df_allp`
- This means there will be two columns with population data:
  + `Population` for US Counties
  + `PopTotal` for the country level
```{r}
df_all %>%
  left_join(df_pop, by = c("Country_Region" = "Location")) ->
  df_allp
```


# How many Country Regions have Multiple Country States?
- Calculate the number of Country States for each Country Region
- Show in descending order of the number of Country_States by Country_Region.
```{r}
df_allp %>% 
  select(Country_Region, Country_State) %>% 
  distinct() %>% 
  group_by(Country_Region) %>% 
  summarise(Num_States = n()) %>% 
  arrange(desc(Num_States))
```


# Analyse Data
1. Create a data frame by with data grouped by `Country_Region`, `Continent` `case_type`, `rank_p` and `rank_d` that summarizes the current totals and the totals as a percentage of total population.
  - Be sure to look at how the data is reported so the numbers make sense.
```{r}
df_allp %>% 
  group_by(Country_Region, Continent, case_type, rank_p, rank_d) %>% 
  summarise(cur_tols = max(Cases), 
            per_tols = (cur_tols/(PopTotal*1000))) %>% 
  distinct() ->
  df_tolcases
df_tolcases
```
  
2. What are the 20 Countries with the most confirmed cases and what is the percentage of their total population affected?
```{r}
df_tolcases %>% 
  filter(case_type == "confirmed_global" | case_type == "confirmed_US") %>% 
  arrange(desc(cur_tols)) %>% 
  head(n = 20) ->
  df_top20_cfm
df_top20_cfm
```

3. What are the 20 Countries with the most deaths and what is the percentage of their total population affected?
```{r}
df_tolcases %>% 
  filter(case_type == "deaths_global" | case_type == "deaths_US") %>% 
  arrange(desc(cur_tols)) %>% 
  head(n = 20) ->
  df_top20_dth
df_top20_dth
```

4. Describe the results based on the totals with the rankings for total population and population density.
- It seems like countries which have higher rank of population and density has more confirmed cases and deaths


# Which countries in the top 20 for percentage of population for cases are Not in the top 20 for the absolute number of cases.  Which countries in the top 20 for percentage of population for deaths are Not in the top 20 for the absolute number deaths?
- Describe the results based on the per population results with the rankings for total population and population density.
```{r}
# Confirmed Cases
df_tolcases %>% 
  filter(case_type == "confirmed_global" | case_type == "confirmed_US") %>% 
  arrange(desc(per_tols)) %>% 
  head(n = 20) %>% 
  anti_join(df_top20_cfm)
# Death Cases
df_tolcases %>% 
  filter(case_type == "deaths_global" | case_type == "deaths_US") %>% 
  arrange(desc(per_tols)) %>% 
  head(n = 20) %>% 
  anti_join(df_top20_dth)
```


# Create two plots, one for the number of cases and one for the number of deaths over time for the top 20 country/region showing each country and faceting by continent with the same scale for the y axis. 
- Use appropriate scales for the axes.
- Create two sets of plots
- Interpret each plot with respect to the total cases/deaths and the path of cases/deaths across different continents.
```{r}
df_top20_cfm %>% 
  ggplot(aes(x = cur_tols, y = as.factor(Country_Region))) +
  geom_boxplot() +
  facet_wrap( ~ Continent) +
  scale_x_log10()

df_top20_dth
```


# Analyze US States Deaths **Extra Credit**

1. Create a data frame with the total deaths and deaths per population for those US states with more than 0 deaths and more than 0 population.
```{r}
df_allp %>% 
  filter(Country_Region == "US") %>% 
  filter(case_type == "deaths_US") %>% 
  group_by(Country_State) %>% 
  summarise(TolDth_byState = max(Cases), 
            Dthper_byState = TolDth_byState/(PopTotal*1000)) %>% 
  distinct() ->
  df_US_Dth
df_US_Dth %>% 
  filter(TolDth_byState > 0) ->
  df_US_Dth
df_US_Dth
```

2. Use an appropriate plot to assess for a linear relationship between total deaths and deaths per population using log scales for x and y axes. Interpret the plot.
```{r}
df_US_Dth %>% 
  ggplot(aes(x = TolDth_byState, y = Dthper_byState)) +
  geom_point() +
  scale_x_log10() +
  scale_y_log10() +
  ggtitle("Covid US Death Data") +
  xlab("Total Deaths by State") +
  ylab("Deaths per Population by State")
# Based on the plot, we can see that there is a positive correlation between total deaths and deaths per population
```

3. Run a linear model to test for a linear relationship and interpret the results in terms of p value, adjusted R-squared and a plot of the residuals.
```{r}
 lm(Dthper_byState ~ TolDth_byState, data  = df_US_Dth) ->
  lmout2
summary(lmout2)
# Based on the result, the p-value < 0.05 which suggests that there is enough evidence to say that there is a linear relationship between total deaths and deaths per population. Adjusted R-squared is 1, meaning 100% of the variation is explained by the regression model, so we can say that this is a good model 
```


